{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8626b27-61a6-45dc-b827-9a67a1d78baa",
   "metadata": {},
   "source": [
    "PROJECT TITLE: DEPRESSION RISK CLASSIFICATION USING MACHINE LEARNING.\n",
    "\n",
    "GOAL: To build a machine learning model that automatically classifies depression severity(Minimal, Mild, Moderate) based on patient responses to the PHQ-9 questionnaire.\n",
    "\n",
    "DATASET: PHQ-9 Dataset from Mendeley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9990b26b-11f4-4e86-b1c7-4d99a57fbb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Missing values in questions: 0\n",
      "   Little interest or pleasure in doing things  \\\n",
      "0                                            2   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "3                                            3   \n",
      "4                                            0   \n",
      "\n",
      "   Feeling down, depressed, or hopeless  \\\n",
      "0                                     0   \n",
      "1                                     0   \n",
      "2                                     0   \n",
      "3                                     3   \n",
      "4                                     0   \n",
      "\n",
      "   Trouble falling or staying asleep, or sleeping too much  \\\n",
      "0                                                  0         \n",
      "1                                                  3         \n",
      "2                                                  0         \n",
      "3                                                  0         \n",
      "4                                                  0         \n",
      "\n",
      "   Feeling tired or having little energy  Poor appetite or overeating  \\\n",
      "0                                      0                            0   \n",
      "1                                      3                            3   \n",
      "2                                      0                            0   \n",
      "3                                      3                            2   \n",
      "4                                      0                            0   \n",
      "\n",
      "   Feeling bad about yourself—or that you are a failure or have let yourself or your family down  \\\n",
      "0                                                  0                                               \n",
      "1                                                  0                                               \n",
      "2                                                  0                                               \n",
      "3                                                  0                                               \n",
      "4                                                  0                                               \n",
      "\n",
      "   Trouble concentrating on things, such as reading the newspaper or watching television  \\\n",
      "0                                                  0                                       \n",
      "1                                                  2                                       \n",
      "2                                                  1                                       \n",
      "3                                                  0                                       \n",
      "4                                                  0                                       \n",
      "\n",
      "   Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual  \\\n",
      "0                                                  2                                                                                                                        \n",
      "1                                                  2                                                                                                                        \n",
      "2                                                  0                                                                                                                        \n",
      "3                                                  0                                                                                                                        \n",
      "4                                                  2                                                                                                                        \n",
      "\n",
      "   Thoughts that you would be better off dead or of hurting yourself in some way  \n",
      "0                                                  0                              \n",
      "1                                                  2                              \n",
      "2                                                  0                              \n",
      "3                                                  0                              \n",
      "4                                                  0                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_5996\\1556778558.py:18: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(level=0, axis=1).first()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#loading the dataset\n",
    "df =pd.read_csv(r\"C:\\Users\\ADMIN\\Downloads\\PHQ-9_Dataset_5th Edition.csv\")\n",
    "\n",
    "\n",
    "# Clean Headers\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# We group columns by their name and keep only the first instance.\n",
    "df = df.groupby(level=0, axis=1).first()\n",
    "\n",
    "# 4. Define Questions\n",
    "phq_questions = [\n",
    "    'Little interest or pleasure in doing things',\n",
    "    'Feeling down, depressed, or hopeless',\n",
    "    'Trouble falling or staying asleep, or sleeping too much',\n",
    "    'Feeling tired or having little energy',\n",
    "    'Poor appetite or overeating',\n",
    "    'Feeling bad about yourself—or that you are a failure or have let yourself or your family down',\n",
    "    'Trouble concentrating on things, such as reading the newspaper or watching television',\n",
    "    'Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual',\n",
    "    'Thoughts that you would be better off dead or of hurting yourself in some way'\n",
    "]\n",
    "\n",
    "# 5. Define Mapping\n",
    "phq_mapping = {\n",
    "    'Not at all': 0,\n",
    "    'Several days': 1,\n",
    "    'More than half the days': 2,\n",
    "    'Nearly every day': 3\n",
    "}\n",
    "\n",
    "# Apply Cleaning & Mapping\n",
    "for col in phq_questions:\n",
    "    # Check if column exists to avoid KeyError\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().map(phq_mapping)\n",
    "\n",
    "print(\"Success! Missing values in questions:\", df[phq_questions].isna().sum().sum())\n",
    "print(df[phq_questions].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd6acc9-173a-4692-b968-d151a3ec05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                                                                                                                                                  Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                  --------------  ----- \n",
      " 0   Age                                                                                                                                                                     682 non-null    int64 \n",
      " 1   Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                           682 non-null    int64 \n",
      " 2   Feeling down, depressed, or hopeless                                                                                                                                    682 non-null    int64 \n",
      " 3   Feeling tired or having little energy                                                                                                                                   682 non-null    int64 \n",
      " 4   Financial Pressure                                                                                                                                                      682 non-null    object\n",
      " 5   Gender                                                                                                                                                                  682 non-null    object\n",
      " 6   Little interest or pleasure in doing things                                                                                                                             682 non-null    int64 \n",
      " 7   Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual  682 non-null    int64 \n",
      " 8   PHQ_Severity                                                                                                                                                            682 non-null    object\n",
      " 9   PHQ_Total                                                                                                                                                               682 non-null    int64 \n",
      " 10  Poor appetite or overeating                                                                                                                                             682 non-null    int64 \n",
      " 11  Sleep Quality                                                                                                                                                           682 non-null    object\n",
      " 12  Study Pressure                                                                                                                                                          682 non-null    object\n",
      " 13  Thoughts that you would be better off dead or of hurting yourself in some way                                                                                           682 non-null    int64 \n",
      " 14  Trouble concentrating on things, such as reading the newspaper or watching television                                                                                   682 non-null    int64 \n",
      " 15  Trouble falling or staying asleep, or sleeping too much                                                                                                                 682 non-null    int64 \n",
      "dtypes: int64(11), object(5)\n",
      "memory usage: 85.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef2082-b996-4b9e-8d77-107c82dab156",
   "metadata": {},
   "source": [
    "From the dataset above, we can see that it contains 682 individuals assessed using the PHQ-9 depression screening questionnaire along with contextual factors such as age, gender, sleep quality, study pressure, financial pressure. \n",
    "\n",
    "Also, each response is categorical, i.e, not at all, several days, more than half days and nearly every day. These are ordinal variables, not nominal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9788bef-3692-464a-a81e-18c67002b178",
   "metadata": {},
   "source": [
    "\n",
    "We will now Prepare the Target(PHQ_Severity)\n",
    "\n",
    "Our target variable is categorical(e.g. severe, mild). We map these categories to an ordered scale of: \n",
    "\n",
    " 0: None-Minimal\n",
    "\n",
    " 1: Mild\n",
    "\n",
    " 2: Moderate\n",
    "\n",
    " 3: Moderately Severe\n",
    "\n",
    " 4: Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42523782-ac24-4281-a3fb-9070932627c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PHQ_severity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PHQ_severity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#checking unique features to ensure we map correctly\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique Severity Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHQ_severity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Defining Target Mapping(ordinal)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m severity_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMild\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone-minimal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Handling potential variation in data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PHQ_severity'"
     ]
    }
   ],
   "source": [
    "#checking unique features to ensure we map correctly\n",
    "print(\"Unique Severity Labels:\", df['PHQ_severity'].unique())\n",
    "\n",
    "#Defining Target Mapping(ordinal)\n",
    "severity_mapping = {\n",
    "    'Minimal': 0,\n",
    "    'Mild': 1,\n",
    "    'Moderate': 2,\n",
    "    'Moderately severe': 3,\n",
    "    'Severe': 4,\n",
    "    'None-minimal': 0 # Handling potential variation in data\n",
    "}\n",
    "\n",
    "# 3. Apply Mapping\n",
    "df['Severity_Encoded'] = df['PHQ_Severity'].str.strip().map(severity_mapping)\n",
    "\n",
    "# 4. Drop rows where target might be missing\n",
    "df = df.dropna(subset=['Severity_Encoded'])\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df['Severity_Encoded'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2747f124-ec7d-4f20-9222-16588e7d88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab7c67-77fb-4e17-9c89-f9d082c85f5a",
   "metadata": {},
   "source": [
    "We now want to define the 9 PHQ questions(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83732ea4-d162-4b36-a486-452c21ee574e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d97b382-db73-47f1-8a48-4dd0da6d719f",
   "metadata": {},
   "source": [
    "We will now define the mapping: We will map them in the following manner:\n",
    "\n",
    "# Response                Value\n",
    "\n",
    "Not at all                0\n",
    "\n",
    "Several days              1\n",
    "\n",
    "More than half the days   2\n",
    "\n",
    "Nearly every day          3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5b0cc-f0a4-4ead-a473-18508b541443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158881c-7812-4413-a7bc-297ebde1adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdce725-c9ce-4109-a299-48ba4dd79e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c13674-6976-43a5-984c-7daea893b031",
   "metadata": {},
   "source": [
    "We are now encoding other categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112c3581-5b2e-479d-812c-592403dd9d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7e6dfe-c30a-4048-ba26-ea6772b9f551",
   "metadata": {},
   "source": [
    "We now want to do ordinal mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feceaa04-6f55-42df-ad03-f932cba5c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mappings = {\n",
    "    'Sleep Quality': {'Worst': 0, 'Average': 1, 'Good': 2},\n",
    "    'Study Pressure': {'Bad': 0, 'Average': 1, 'Good': 2},\n",
    "    'Financial Pressure': {'Bad': 0, 'Average': 1, 'Good': 2}\n",
    "}\n",
    "# Applying them\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    df[col] = df[col].map(mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e182fed-6ad4-4ee9-9919-96f02aa28a3d",
   "metadata": {},
   "source": [
    "We now want to do Feature-Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ed59bf-be8a-475b-8e3a-b7f08b027fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 14) (682,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['HighRisk_Depression'])\n",
    "\n",
    "y = df['HighRisk_Depression']\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973e86c-86d6-4ad4-af35-19b0cf09d09e",
   "metadata": {},
   "source": [
    "We will now perform Stratified Train-Test Split. The reason why we are using stratified sampling is to preserve class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9724503b-a703-4d5b-9263-8bdac0336a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighRisk_Depression\n",
      "0    0.528376\n",
      "1    0.471624\n",
      "Name: proportion, dtype: float64\n",
      "HighRisk_Depression\n",
      "0    0.532164\n",
      "1    0.467836\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y,test_size =0.25, stratify= y,random_state=42\n",
    ")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca730470-3454-4f72-a82d-4577acc4d7f0",
   "metadata": {},
   "source": [
    "From the results above, we can see that the dataset ehibits a slight class imbalance with approximately 53% low risk and 47% high risk cases. Our baseline accuracy is 53% and any model we will build must outperform this to be meaningful. The reason why this baseline is critical is that it can be used for model comparison and demonstrating improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c994baf-dcf4-4d5f-9847-b056d58b0df5",
   "metadata": {},
   "source": [
    "The ordinal variables were encoded using domain-informed mappings and nominal variables were one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf018bc4-bfe9-489e-a56e-288140606627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding nominal columns\n",
    "nominal_cols = ['Gender']\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=nominal_cols, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=nominal_cols, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cb35d-8010-44eb-836d-e22d64c5510a",
   "metadata": {},
   "source": [
    "We will do Feature Matrix to exclude labels and text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b39f46a-84ff-4b3e-80c6-1a5c80cd67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Matrix\n",
    "X = df.drop(columns=[\n",
    "    'HighRisk_Depression'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc026e09-634a-42ba-91fb-83fd611fe739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                                                                                                                                                  Non-Null Count  Dtype\n",
      "---  ------                                                                                                                                                                  --------------  -----\n",
      " 0   Little interest or pleasure in doing things                                                                                                                             682 non-null    int64\n",
      " 1   Feeling down, depressed, or hopeless                                                                                                                                    682 non-null    int64\n",
      " 2   Trouble falling or staying asleep, or sleeping too much                                                                                                                 682 non-null    int64\n",
      " 3   Feeling tired or having little energy                                                                                                                                   682 non-null    int64\n",
      " 4   Poor appetite or overeating                                                                                                                                             682 non-null    int64\n",
      " 5   Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                           682 non-null    int64\n",
      " 6   Trouble concentrating on things, such as reading the newspaper or watching television                                                                                   682 non-null    int64\n",
      " 7   Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual  682 non-null    int64\n",
      " 8   Thoughts that you would be better off dead or of hurting yourself in some way                                                                                           682 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 48.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check how many non-null values are in these columns\n",
    "print(df[phq_columns].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef552f45-5f18-4e1d-b8e2-cbbacf5dcf07",
   "metadata": {},
   "source": [
    "We will now handle the missing values(NaNs) in our training data and we will use a SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce9345a2-8d08-4131-a85c-49c26ed38ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Initialize the Imputer (using median is best for ordinal health data)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# 2. Fit and transform the training data, and transform the test data\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "print(\"Missing values handled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c4719-9128-44c8-8df5-4f1f5b3e30bd",
   "metadata": {},
   "source": [
    "We now need to do Feature scalling because PHQ Scores, age, pressure variables are on different scales and also it prevents models from being biased towards large-value features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77214e3-24f4-40ab-8f9f-e7c3aa5825e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step is doing numeric feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# we will use the imputed here\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98184d-958a-4d9f-aa04-b9eace663b4e",
   "metadata": {},
   "source": [
    "\n",
    "We now want to do Logistic Regression and it will be our Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d57d5ae-8707-4e9b-b093-b972734fdc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Fitted Successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initializing with 'balanced' weights to handle the slight class imbalance\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "print(\"Logistic Regression Model Fitted Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e84e6-9927-4c01-9655-00cf70c08b93",
   "metadata": {},
   "source": [
    "We will now do model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73d85eda-c7d4-4f50-9b11-bda502013033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        91\n",
      "           1       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[91  0]\n",
      " [ 0 80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bb776-75e7-41e7-b1a6-281fc4b32ae2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9806ee44-ca8b-40dd-aeed-58787ef12aa3",
   "metadata": {},
   "source": [
    "Tree-Based Model(Random Forest)\n",
    "\n",
    "We are doing the Random forest because it handles non-linear relationships, it is robust to noise and works well with mixed feature types. It also captures symptom interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65acb548-d684-41c2-a4c6-dd105f051382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        91\n",
      "           1       0.98      0.99      0.98        80\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "[[89  2]\n",
      " [ 1 79]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf= RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    class_weight = 'balanced',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4c077-8769-41a9-b0bb-ec22d2bb3621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
